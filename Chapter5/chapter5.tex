\chapter{The Local Planning Semantics}\label{chap:5}
\minitoc
\label{sec3}

In Chapter~\ref{chap:3}, we presented a timed automata model for representing timed systems
with multiparty interactions in a distributed setting. Such model provides details on how 
an implementation of multiparty interactions can be derived based on a partial view of 
the system. It also explicitly  expresses the ongoing communication mechanism using simpler 
primitives such as exchange of messages. However, this type of model is constrained by the fact
that the response time of the schedulers is fast enough to not impact the behavior of the 
overall system.

In~\cite{ahlem_these}, a solution based on an \emph{early decision making} approach was 
presented to cope with this problem. The main idea of this method was to anticipate components
executions ahead such that the latency induced by the scheduling mechanism does not affect
the system. To achieve this, schedulers plan ahead the execution of interactions
and notify the corresponding components in advance. 
In this approach, it was suggested that schedulers are required to observe an additional 
subset of components, called \emph{observed components}, not participating in the planned 
interactions, in order to achieve global deadlines. 
However, the characterization of the set of observed components is incomplete. In fact this set
is greater than the presented characterization, and in many cases is it includes all the 
components of the system. This is mainly due to the nature of the location invariants 
(local constraints that propagate on the global level). 
Moreover, the proposed approach does not provide any proof of correctness regarding deadlocks. 
Intuitively, executions resulting from such method are included in the possible executions
of the initial model. This means that the resulting behavior is a restriction of the initial 
behavior which in some cases may introduce blocking situations. 
 
This motivates the introduction of the \emph{\lpsb} (LPS). It is based on the same idea of 
early decision making but with the difference that we do not reason on the Send/Receive model
as in~\cite{ahlem_these}, but on a higher level of abstraction closer to the initial model.
This choice was driven by two main points: \emph{(1)} facilitate the comparison with the 
initial behavior of the standard semantics and the fact that \emph{(2)} it is much more suited 
for verification. 
The \lps differs from
the standard semantics of timed automata in two main aspect: \emph{(i)} interactions executions
are based only on partial state of the system, that is, based only on the state of components
participating in the considered interaction. Thus, it allows to decide locally without 
monitoring the entire system. \emph{(ii)} it distinguishes between the 
execution decision of an interaction (its \emph{planning}), and the execution itself.
This distinction allows us to impose a delay between the planning of an interaction and 
its execution. The latter is constrained by the (maximal) communication latency induced 
by execution platforms, which is a parameter of the semantics.
Trivially, this semantics is correct in the sense that it refines (it is included in) the 
standard semantics.
However, being based on local states, planning decisions are too permissive and may 
introduce deadlocks when they are not compatible with the global state of the system.

\section{Local Planning of Interactions}
\subsection{Definition of the LPS}
\label{subsec:wp} 
Let $S=\gamma(B_1,\cdots,B_n)$ be a composition of components $B_1$, \ldots, $B_n$ with
disjoint set of locations, actions and clocks.
We define the predicate $\plnIntxt{\alpha}{d}$ characterizing states $(\loc, \val)$
from which an interaction $\alpha = \{ a_i \}_{i \in I} \in \gamma$ is enabled in 
$d \in \realpoz$ units of time, that is, if time progresses by $d$ units of time.
It is formalized as follows:
%It is characterized by:
\begin{equation}\label{eq:enf1}
  \plnIntxt{\alpha}{d}\text{ holds at }(\loc,\val)\Leftrightarrow\enabled{\alpha}\text{ holds at
  }(\loc,\val+d)
\end{equation}
%Notice that for an interaction $\alpha$ the predicate $\plnIntxt{\alpha}{d}$ depends only 
%on states of components of $\p{\alpha}$, which motivates the following property.

\begin{property}\label{pt:plnIn1}
Let $(\loc,\val)$ be a state of the composition $S$. For any interactions $\alpha,\beta\in\gamma$
such that, $(\loc,\val)\transit{\beta}_{\gamma}(\loc',\val')$ and $\p{\alpha}\cap\p{\beta}=
\emptyset$, if $\plnIntxt{\alpha}{d}$ holds at state $(\loc,\val)$ then it still 
holds at state $(\loc',\val')$.
\end{property}
This property derives directly from the fact that executing an interaction $\beta$ does 
not change the states of components participating in an interaction $\alpha$, 
provided that $\alpha$ and $\beta$ have disjoint sets of participating components, 
and thus, $\plnIntxt{\alpha}{d}$ is not affected by the execution of $\beta$ in this case.
In the following, we consider a slightly different definition of conflicts than the one
presented in Chapter~\ref{chap:3} and Chapter~\ref{chap:4}. 
We say that two interactions $\alpha$ and $\beta$ \emph{conflicts} when 
they have common participating components, that is, when $\p{\alpha}\cap\p{\beta}\neq\emptyset$, 
and we write $\alpha\#\beta$.
We denote by $conf(\alpha)$ the set of interactions conflicting with $\alpha$, that is, 
$conf(\alpha) = \{ \beta \in \gamma \ | \ \alpha\#\beta \}$.

\begin{property}\label{pt:plnIn2}
Let $(\loc,\val)$ and $(\loc,\val+d')$, with $d'\in\realpos$ be two states of 
the composition $S$. For an interaction $\alpha\in\gamma$, if $\plnIntxt{\alpha}{d}$ 
holds at state $(\loc,\val)$ then $\plnIntxt{\alpha}{d-d'}$ 
also holds at any state $(\loc,\val+d')$ such that $d'\le d$.
\end{property}
\noindent This property can be found directly by writing expression~\ref{eq:enf1} on state 
$(\loc,\val+d')$.

As previously explained, due to communication latencies induced by execution platforms, 
we assume that interactions cannot be planned in $d$ units of time if $d < \hmin$, 
where $\hmin \in \integerpoz$ is a parameter representing the \emph{minimal planning horizon}, 
which should represent the upper bound response time of schedulers when scheduling interactions.
The latter is constrained by the communication latencies between schedulers and both components
and the conflict resolution layer as well as the evaluation of interactions constraints. 
Notice that for the sake of simplicity, we consider a global parameter $\hmin$ but 
we could also assume different parameters for each interaction.
Additionally, we also consider upper bound planning horizons 
$\hmax : \gamma \to \integerpoz\cup\{ +\infty \}$ 
for each interaction such that for any $\alpha\in\gamma$ we have $\hmax(\alpha) \geq \hmin$.
We denote by $\hmaxt$ the upper planning horizon assigning infinity to every $\hmax(\alpha)$.
These bounds restrict planning horizons of interactions such that every interaction $\alpha$ 
can be planned only using a horizon $d$ satisfying $\hmin \leq d \leq \hmax(\alpha)$,
meaning that every component $B\in\p{\alpha}$ will be blocked for a duration in
$[\hmin,\hmax(\alpha)]$ each time $\alpha$ is planned. 
Observe that while $\hmin$ represents the worst case estimation of the 
scheduler response time, the parameters $\hmax(\alpha)$ will be used later 
to find a strategy that avoids deadlocks by restricting the amount of time components 
can be blocked for.

For an interaction $\alpha$, we define the predicate $\plntxt{\alpha}$ 
characterizing states from which $\alpha$ can be planned in a delay respecting 
the planning horizons $\hmin$ and $\hmax(\alpha)$, that is:
\begin{displaymath}
  \plntxt{\alpha}\Leftrightarrow \bigvee_{d\in[\hmin,\hmax(\alpha)]} \plnIntxt{\alpha}{d},
\end{displaymath}
Remark that the above corresponds exactly with the definition of $\enabledbackwardb{\alpha}{l}
{u}$ given in Chapter~\ref{chap:2}. This allows to write:
\begin{equation}\label{eq:pln}
 \plntxt{\alpha}=\enabledbackwardb{\alpha}{\hmin}{\hmx}
\end{equation}

\begin{definition}[Plan]\label{def:plan}
A plan $\pi$ is a function $\pi:\gamma \to\realpoz \cup \{ +\infty \}$ defining relative times
for executing interactions, with the convention that an interaction $\alpha$ is planned to 
execute in $\pi(\alpha)$ time units only if $\pi(\alpha) < +\infty$.
Plans satisfy that for any two interactions $\alpha \neq \beta$, such that $\pi(\alpha) < +\infty$
and $\pi(\beta) < +\infty$, the interactions $\alpha$ and $\beta$ are not conflicting 
(i.e. $\neg(\alpha\#\beta)$).
\end{definition}
We denote by $\pi_0$ the plan assigning $+\infty$ to every interaction of $\gamma$, that is,
$\forall\alpha\in\gamma,\pi_0(\alpha)=+\infty$. For a plan $\pi$, we consider its minimum value
$\pmin=\min\ \{\pi(\alpha)|\alpha\in\gamma\}$. 
We also denote by $\confl(\pi)$ the set of interactions conflicting with the plan $\pi$, i.e., 
$\confl(\pi) = \{ \alpha \ | \ \exists \beta \# \alpha.$ $ \pi (\beta) < +\infty \}$, 
and $\p{\pi}$ the set of components participating in interactions planned by 
$\pi$, i.e., $\p{\pi}=\{B_i\ |\ \exists\alpha\ . \ \pi(\alpha)<+\infty\wedge B_i\in\p{\alpha} \}$.
Notice that since $\pi$ stores relative times, whenever time progresses by $d$, the value 
$\pi(\alpha)$ assigned by $\pi$ to an interaction $\alpha$ should be decreased by $d$ 
until it reaches $0$, meaning that $\alpha$ has to execute.
We write $\pi-d$ to describe the progress of time 
over the plan, that is, $(\pi-d)(\alpha) = \pi(\alpha) - d$ for interactions $\alpha$ 
such that $\pi(\alpha) < +\infty$.
Similarly, $\pi [ \alpha \mapsto d ]$ assigns relative time $d$ to $\alpha$, 
$\alpha \notin conf(\pi)$, into existing plan $\pi$, i.e. $(\pi [ \alpha \mapsto d ])
(\beta) = d$ for $\beta = \alpha$, $(\pi [ \alpha \mapsto d ])(\beta) = \pi(\beta)$ 
otherwise.

\begin{definition}[Local Planning Semantics]\label{def:pln_sem}
Given a set of components $\{B_1,\cdots,B_n\}$ and an interaction set $\gamma$,
we define the \lps (LPS) of the composition $\gamma(B_1,\cdots,B_n)$,
as the TTS $(\Q_p,q_{p_0},\gamma\cup\realpos\cup(\gamma\times\realpoz),\tranbp{}{3})$ where:
\begin{itemize}
  \item $\Q_p=\Loc\times\mathcal{V}(\X)\times\Pi$, where $\Loc$ is the set of global locations,
    $\mathcal{V}(\X)$ is the set of global clock valuations, and $\Pi$ is the set of plans.
  \item $(\gamma\times\realpoz)$ defines the action of planning interactions of $\gamma$ and 
    their relative times. It represents the additional label besides the progress of time
    $(\realpos)$ and the execution of interactions ($\gamma$) present in the standard semantics.
  \item $\tranbp{}{3}$ is the set of transitions defined by the rules:
    \begin{itemize}%[leftmargin=0em]
      \item $(\loc,\val,\pi)\tranbp{(\alpha,d)}{4}(\loc,\val,\pi [ \alpha\mapsto d ])$ 
        for $\alpha \in \gamma$, $\hmin\le d\le\hmx$ and $d\neq+\infty$ 
        if $\alpha \notin\confl(\pi)$ and 
        $\plnIntxt{\alpha}{d}$ holds on $(\loc,\val,\pi)$.

      \item $(\loc,\val,\pi)\tranbp{\alpha}{3}(\loc',\val', \pi [ \alpha\mapsto+\infty ])$ 
        for $\alpha \in \gamma$ if $\pi(\alpha) = 0$ and $(\loc,\val)\transit{\alpha}_{\gamma}
        (\loc',\val')$.

      \item $(\loc,\val,\pi)\tranbp{d}{3}(\loc,\val+d,\pi-d)$ for 
        $d \le \pmin$, $\loc = (\loc_1, \ldots, \loc_n)$, if 
        $(\val + d + \hmin)\models\I_i(\loc_i)$ for components $B_i \notin \p{\pi}$.
  \end{itemize}
\end{itemize}
\end{definition}

Remark that in the above definition as well as in what follows, predicates defined on states 
$(\loc,\val) \in \Q_g=\Loc\times\mathcal{V}(\X)$ of the standard semantics are 
straightforwardly interpreted on states $(\loc,\val,\pi) \in \Q_p$ considering the 
projection $(\loc,\val)$ of $(\loc,\val,\pi)$ on $\Q_g$.

States of the \lpsabrb do not include only locations and clock valuations, 
but also the relative execution times of the planned interactions stored by $\pi$.
Initially, no interaction is planned, that is, initial states are of the form 
$(\loc_0,\val_0,\pi_0)$.
Planning an interaction $\alpha$ to be executed at a relative time $\hmin\le d\le\hmax
(\alpha)$ corresponds to the operation $\pi [ \alpha\mapsto d  ]$ on the plan, 
which can only be done if $\alpha$ is not conflicting with the latter, and becomes enabled if 
time progresses by $d$ (i.e. if $\plnIntxt{\alpha}{d}$).
Additionally, time progress not only updates clock values but also the plan by 
decreasing the relative execution times of the planned interactions.
To force the execution of planned interactions when their relative execution times reach $0$, 
time cannot progress more than the relative execution times of the interactions 
(more than $d \le \pmin$).
As for the standard semantics, time progress is limited by the location invariants 
of the components, but with the following significant difference.
Components $B_i \in \p{\pi}$ participating in planned interactions behave as in the standard 
semantics, that is, time can progress until their invariants become urgent.
For components $B_i \notin \p{\pi}$, i.e., that are not participating in planned interactions, 
we take into account the minimal delay $\hmin$ needed for planning and then executing an 
interaction: in components $B_i \notin \p{\pi}$ time can progress only up to $\hmin$ time 
units before the urgency of their location invariants.
By doing so, we ensure that there always remains enough time to plan interactions involving 
$B_i \notin \p{\pi}$ , if they exist, and execute them before their invariants 
expire.
 
\begin{example}
  \label{exp:dl}
  Let us consider the following execution sequence for example of Figure~\ref{fig:tm} under 
  the LPS with $\hmin = 2$ and $\hmax=\hmaxt$. 
%\begin{displaymath}
    \begin{align*}
      &((\loc_0^1,\loc_0^2,\loc_0^3,\loc_0^4),(0,0,0),+\infty)&\tranbp{(\alpha_1,26)}{6} 
      &((\loc_0^1,\loc_0^2,\loc_0^3,\loc_0^4),(0,0,0),\{\alpha_1\mapsto26\})\tranbp{26}{6}\\
      &((\loc_0^1,\loc_0^2,\loc_0^3,\loc_0^4),(26,26,26),\{\alpha_1\mapsto0\})&\tranbp{\alpha_1}{6}  
      &((\loc_1^1,\loc_1^2,\loc_0^3,\loc_0^4),(26,26,26),+\infty)\tranbp{(\alpha_3,2)}{6}\\
      &((\loc_1^1,\loc_1^2,\loc_0^3,\loc_0^4),(26,26,26),\{\alpha_3\mapsto2\})&\tranbp{2}{6}  
      &((\loc_1^1,\loc_1^2,\loc_0^3,\loc_0^4),(28,28,28),\{\alpha_3\mapsto0\})\tranbp{\alpha_3}{6}\\
      &((\loc_0^1,\loc_2^2,\loc_0^3,\loc_0^4),(0,28,0),+\infty)&\tranbp{(\alpha_2,26)}{6} 
      &((\loc_0^1,\loc_2^2,\loc_0^3,\loc_0^4),(0,28,0),\{\alpha_2\mapsto26\})\tranbp{26}{6}\\
      &((\loc_0^1,\loc_2^2,\loc_0^3,\loc_0^4),(26,54,26),\{\alpha_2\mapsto0\})&\tranbp{\alpha_2}{6} 
      &((\loc_1^1,\loc_2^2,\loc_1^3,\loc_0^4),(26,54,26),+\infty)\tranbp{(\alpha_4,2)}{6}\\
      &((\loc_1^1,\loc_2^2,\loc_1^3,\loc_0^4),(26,54,26),\{\alpha_4\mapsto2\})&\tranbp{2}{6}  
      &((\loc_1^1,\loc_2^2,\loc_1^3,\loc_0^4),(28,56,28),\{\alpha_4\mapsto0\})\tranbp{\alpha_4}{6}\\
      &((\loc_0^1,\loc_2^2,\loc_2^3,\loc_0^4),(28,0,0),+\infty)&\tranbp{(\alpha_6,30)}{6}  
      &((\loc_0^1,\loc_2^2,\loc_2^3,\loc_0^4),(28,0,0),\{\alpha_6\mapsto30\})
    \end{align*}
 % \end{displaymath}
This execution sequence represents a path that alternates plan actions, time progress and 
execution of some interactions, and leads to the action-time-lock state 
$((\loc_0^1,\loc_2^2,\loc_2^3,\loc_0^4),(0,0,28),\{\alpha_6\mapsto30\})$. 
In fact, the location invariant $x\leq30$ in component $T_1$, imposes the 
planning of interaction $\alpha_7$ at the latest $h_{min}$ units of time before it becomes 
urgent. However, since interaction $\alpha_6$ was planned in 28 units of time, $\alpha_7$ 
cannot be planned since it is conflicting with $\alpha_6$.
This execution sequence shows that a given system action-time-locks under the \lps, even if 
it is deadlock-free in the standard semantics. 
\end{example}

\subsection{Properties of the LPS}\label{subsec:planprop}
We use weak simulation to compare models interpreted with
the standard semantics and with the local planning semantics,
by considering the planning transitions unobservable.
As shown in Example~\ref{exp:dl}, the \lpsabrb does not preserve the deadlock freedom 
property of our system.
Nevertheless, the following proves weak simulation relations between the two semantics.

\begin{lemma}\label{lem:pi_pln}
  Given a reachable state $(\loc,\val,\pi)$ of the \lpsabr. If for $\alpha\in\gamma$, 
  $\pi(\alpha) < +\infty \Rightarrow \plnIntxt{\alpha}{\pi(\alpha)}$.
\end{lemma}


\begin{proposition}\label{prop:r1}
An interaction can execute from a state $(\loc,\val,\pi)$ in the \lpsabrb semantics only if 
it can execute from $(\loc,\val)$ in the standard semantics, that is:
\begin{displaymath}
      \forall\alpha\in\gamma.(\loc,\val,\pi)\tranbp{\alpha}{3}(\loc',\val',\pi')
      \Rightarrow (\loc,\val)\transit{\alpha}_{\gamma}(\loc',\val').
\end{displaymath}
\end{proposition}

Proposition~\ref{prop:r1} is a consequence of Lemma~\ref{lem:pi_pln}: an interaction $\alpha$ 
can execute in the \lps if and only if $\pi(\alpha) = 0$ (see Definition~\ref{def:plan}).
That is, a state $(\loc,\val,\pi)$ of the \lpsabrb from which $\alpha$ can execute satisfies 
$\plnIntxt{\alpha}{0}$ or equivalently $\enabled{\alpha}$, which demonstrates that $\alpha$ 
can execute from $(\loc,\val)$ in the standard semantics.

\begin{proposition}\label{prop:r2}
Time can progress by $d$ at a state $(\loc,\val,\pi)$ in the \lps only if time can 
progress by $d$ at $(\loc,\val)$ in the standard semantics, that is:
\begin{displaymath}
      \forall d\in\realpos.(\loc,\val,\pi)\tranbp{d}{3}(\loc',\val',\pi')
      \Rightarrow (\loc,\val)\transit{d}_{\gamma}(\loc',\val').
\end{displaymath}
\end{proposition}

Proposition~\ref{prop:r2} is a direct consequence of the definition of time progress in 
the \lps which is a restriction of the one in the standard semantics.

\begin{corollary}\label{cr:reach}
If a state $(\loc,\val,\pi)$ is reachable in the \lpsb, then the state $(\loc,\val)$ is 
  reachable in the standard semantics.
\end{corollary}

Corollary~\ref{cr:reach} is obtained from Propositions~\ref{prop:r1} and~\ref{prop:r2} and the 
fact that planning transitions (labeled by $(\alpha,d)$) affect only the plan $\pi$ in 
states $(\loc,\val,\pi)$ of the \lpsabr.

The definition of weak simulation (Definition~\ref{def:wsim})
is based on the unobservability of $\beta-$transitions. 
In our case, $\beta-$transitions corresponds to planning transitions.
Let $\tts_g$ and $\tts_p$ be respectively the underlying timed transition systems of the standard
semantics and the \lps respectively.
\begin{corollary}\label{cr:sim}
  $\tts_p\simuw{R} \tts_g$ with $R=\{((\q,\pi);\q)\in\Q_p\times\Q_g\}$.
\end{corollary}

Corollary~\ref{cr:sim} corresponds to a notion of correctness of the \lpsb: any execution in 
the \lpsabrb corresponds to an execution in the standard semantics.
In addition, if interactions are allowed to be planned with relative execution times of $0$ 
(i.e. $\hmin = 0$) then timeless planning of interactions becomes possible. Thus, the planning 
semantics simulates the standards semantics in that case.
\begin{corollary}
  $\tts_g\simuw{R} \tts_p$ with $R=\{(\q;(\q,\pi))\in\Q_g\times\Q_p\}$ for $\hmin=0$.
\end{corollary}

However, this is no longer true in general if  $\hmin > 0$ which means that not all execution 
sequences of the standard semantics are preserved by the \lpsb.

\begin{corollary}\label{cr:zeno}
  If $\tts_g$ is zeno runs free then $\tts_p$ is too.
\end{corollary}
Corollary~\ref{cr:zeno} states that the $\lpsabr$ does not introduce any zeno run if
the standard semantics is free from the latter. It is a direct consequence of 
Corollary~\ref{cr:sim} and the fact that it is not possible to have infinite sequences of 
planning transitions without interaction execution ($\gamma$ is finite and planning times are
bounded).
\begin{proposition}\label{prop:deadlock-timelock}
If $\tts_g$ is deadlock free, then $\tts_p$ is deadlock free if it is action-timelock-free.
  
\end{proposition}

Before proving the above proposition, we need the following two lemmas that allows to reason
on some properties of interest on states of the local planning semantics.
We denote by $wait(\loc,\val,\pi)$ the set of allowed waiting times at state $(\loc,\val,\pi)$,
that is:
\begin{displaymath}
  wait(\loc,\val,\pi)=\{0\}\cup\{d\in\realpos|(\loc,\val,\pi)\tranbp{d}{3}
  (\loc,\val+d,\pi-d)\}
\end{displaymath}
We also put $\max(wait(\loc,\val,\pi))$ to denote the maximal waiting time at state 
$(\loc,\val,\pi)$. Notice that $\max(wait(\loc,\val,\pi))$ may not be defined in some cases.
In fact, we are not interested in its actual existence but rather in the fact that it is
bounded ($<+\infty$) or not.
\begin{lemma}\label{lemma:wait}
  Let $(\loc,\val,\pi)$ be a reachable state of the \lpsb. For $k\in\realpoz$, such
  that $k=\max(wait(\loc,\val,\pi))$, we have the following properties: 
  \begin{description}
    \item[\namedlabel{p1}{P1}] If $k<+\infty$ then $(\loc,\val,\pi)\tranbp{k}{3}
      (\loc,\val+k,\pi-k)\wedge wait(\loc,\val+k,\pi-k)=\{0\}$
    \item[\namedlabel{p2}{P2}] If $\pi\neq\pi_0$ then $k\le\pmin$
  \end{description}
\end{lemma}
The above lemma is direct consequence of Definition~\ref{def:pln_sem}. 
\begin{lemma}\label{lemma:deadlock}
        Let $(\loc,\val,\pi)$ be a reachable state of the \lps. 
        If $ \ \forall d\in\realpos. \ (\loc,\val,\pi)\tranbp{d}{3}
          (\loc,\val+d,\pi-d)\wedge\neg\plntxt{\alpha}$ at $(\loc,\val,\pi)$,
          then we have $\neg\enabled{\alpha}$ at $(\loc,\val+d,\pi-d)$ with 
          $\hmin\le d\le\hmx$.
\end{lemma}
Lemma~\ref{lemma:deadlock} results trivially from the definition of the predicate
$\plntxt{\alpha}$.

\begin{proof}[Proof of Propostion~\ref{prop:deadlock-timelock}]
  We prove Proposition~\ref{prop:deadlock-timelock} by contradiction.
  Let us assume that the system under the standard (resp. local planning) semantics is
  deadlock free (resp. action-time-lock-free).
  Let $(\loc,\val,\pi)$ be a reachable deadlock state of the \lpsabr. We have:
  \begin{displaymath}
    \nexists\sigma\in\gamma\cup(\gamma\times\realpoz),\exists d.\ (\loc,\val,\pi)
    \tranbp{\sigma}{3}(\loc',\val',\pi')
    \vee(\loc,\val,\pi)\tranbp{d}{3}(\loc,\val+d,\pi-d)\tranbp{\sigma}{3}
    (\loc',\val',\pi')
  \end{displaymath}


We distinguish 2 cases:
\paragraph*{Case 1: no interaction is planned (i.e. $\pi =\pi_0$)}
By definition of the \lpsabr, it is clear that for $\pi=\pi_0$, there is no interaction to 
execute from $(\loc,\val,\pi)$ or any of its successor $(\loc,\val+d,\pi-d)$.
\begin{enumerate}
  \item $wait(\loc,\val,\pi)=\{0\}$:\\
    This means that time progress is not allowed at state $(\loc,\val,\pi)$. We also have
    $\nexists\sigma\in(\gamma\times\realpoz).(\loc,\val,\pi)\tranbp{\sigma}{3}(\loc',\val',\pi')$
    (deadlock assumption). We can conclude that $(\loc,\val,\pi)$ is a reachable action-time-lock
    state, which contradicts the assumption that the system under the \lps is 
    action-time-lock-free.
  \item $wait(\loc,\val,\pi)\neq\{0\}$:
    \begin{enumerate}
      \item $\max(wait(\loc,\val,\pi))=+\infty$:\\
      By~\ref{p1} of Lemma~\ref{lemma:wait} we can deduce that $\exists d\ge h_{\min}$ 
      such that $(\loc,\val,\pi)\tranbp{d}{3}(\loc,\val+d,\pi-d)$. 
      We also have from the deadlock assumption and Lemma~\ref{lemma:deadlock}:
      $\bigwedge_{\alpha\in\gamma}\neg\enabled(\alpha)$. Finally, since the state 
      $(\loc,\val+d,\pi-d)$ is reachable in the standard semantics, and by evaluating 
      the deadlock characterization~\ref{eq:dl} on state $(\loc,\val+d,
      \pi-d)$, we can conclude that the system under the standard semantics deadlocks, 
      which contradicts the assumption of deadlock freedom of the system under the standard 
      semantics.
      \item $\max(wait(\loc,\val,\pi))<+\infty$:\\
      Considering that $k=\max(wait(\loc,\val,\pi))$, then we have by~\ref{p1} of 
      Lemma~\ref{lemma:wait}: $(\loc,\val,\pi)\tranbp{k}{3}(\loc,\val+k,\pi-k)\wedge 
      wait(\loc,\val+k,\pi-k)=\{0\}$. Using the deadlock assumption we have: 
      $\bigwedge_{\alpha\in\gamma}\neg\plntxt{\alpha}$ at state $(\loc,\val+k,\pi-k)$.
      Since the system cannot progress beyond this state ($wait(\loc,\val+k,\pi-k)=\{0\}$), 
      we can conclude that $(\loc,\val+k,\pi-k)$ is a reachable action-time-lock state, 
      which contradicts the assumption that the system under the \lps is action-time-lock-free.
      
    \end{enumerate}
\end{enumerate}

\paragraph*{Case 2: at least an interaction is planned (i.e. $\pi \neq \pi_0$)}
Considering that $k=\max(wait(\loc,\val,\pi))$, since $\pi\neq+\infty$, we have by~\ref{p2} of 
Lemma~\ref{lemma:wait}: $k<+\infty\wedge k\le\min\pi$. Using the deadlock assumption we can 
infer that $k<\min\pi$, since 
no execution is possible from $(\loc,\val,\pi)$ or any of its successors. 
This means that $(\loc,\val+k,\pi-k)$ is a reachable action-time-lock state, 
which contradicts the assumption that the system under the \lpsabrb is action-time-lock-free.
\end{proof}

\section{Enforcing Deadlock-Free Planning}
\label{sec4}
As explained in previous section, the \lps is based on local conditions for planning interactions
and may exhibit deadlocks even when the system is deadlock-free with the standard semantics.
Such deadlocks are partly due to the fact that planning an interaction may block, in addition to 
the participating components, extra components whose timing constraints are not considered in
the preconditions of the local planning semantics. 
In this section, we investigate simple execution strategies that only 
restrict the horizon used for planning interactions with upper bounds.
By reducing the period of time during which components are blocked, they tend to remove deadlocks
from the reachable states. 
In what follows, we consider a composition of components $S = \gamma(B_1,\cdots,B_n)$ 
such that it is deadlock free in the standard semantics.

%\begin{corollary}[Sufficient Condition for Deadlock Freedom]
%  \label{cr:suff}
%  If a reachable state of the planning semantics is not an action-time-lock then it is not
%a deadlock.
%\end{corollary}
%Corollary~\ref{cr:suff} is a direct consequence of Proposition~\ref{prop:deadlock-timelock}.
%It affirms that for systems that are initially deadlock-free under the standard semantics, 
%it is sufficient to prove action-time-lock freedom of the \lpsabrb 
%to prove its deadlock freedom.

\begin{proposition}\label{prop:timelocks}
A reachable state $(\loc,\val,\pi)$ of the \lps is an action-time-lock if and only if:
\begin{displaymath}
  \pi>0 \ \wedge \bigwedge_{\alpha \notin conf(\pi)} \hspace*{-2ex} \neg\plntxt{\alpha} \ \wedge
  \hspace*{-1ex} \bigvee_{\substack{\loc_i \in \Loc_i \\ B_i \notin \p{\pi}}} \hspace*{-2ex} 
  \al{\loc_i} \ \wedge (\urg(\loc_i) + \hmin).
\end{displaymath}
\end{proposition}
The above proposition derives directly from the definition of action-time-locks on a state 
of the \lpsb. 
As shown in Example~\ref{exp:dl}, the \lps may introduce deadlocks.
The source of deadlocks is twofold: \emph{(i)} due to the scheduling response time, 
consecutive execution in a component are separated by at least $\hmin$ units of time which may 
be incompatible with its timings constraints, and \emph{(ii)} conditions for planning 
interactions are too permissive as they only take into account timing constraints of 
participating components whereas they may block additional components, namely the ones 
participating in conflicting interactions.
In what follows, we study how to generate planning strategies for preserving 
deadlock freedom by restricting the planning transitions of the \lpsabrb so that deadlock 
states become unreachable.
Such a strategy may not exist when timing constraints cannot accommodate with the 
response time $\hmin$.

From Propostion~\ref{prop:deadlock-timelock}, action-time-lock freedom is a sufficient 
condition for deadlock freedom of the \lpsabr.
By Proposition~\ref{prop:timelocks}, a state $(\loc,\val,\pi)$ is an action-time-lock in the 
\lps if and only if:
\begin{displaymath}
  \pi>0 \ \wedge \ \bigwedge_{\alpha \in \gamma \setminus conf(\pi)} \hspace*{-2ex} \neg
  \plntxt{\alpha} \ \wedge
  \hspace*{-1ex} \bigvee_{\substack{\loc_i \in \Loc_i \\ B_i \notin \p{\pi}}} \hspace*{-2ex} 
  \al{\loc_i} \ \wedge(\urg(\loc_i) + \hmin).
\end{displaymath}
The above predicate characterizes the fact that no interaction can be executed or planned, 
nor time can progress in component $B_i \notin \p{\pi}$.
Consequently, we deduce that a necessary condition of action-time-lock is the existence of a 
component $B_i \notin \p{\pi}$ such that time cannot progress in $B_i$ and $B_i$ cannot be 
planned in an interaction, that is:
\begin{displaymath}
  \bigwedge_{\substack{\alpha \in \gamma(B_i) \setminus conf(\pi)}} \hspace*{-4ex} 
  \Big(\neg\plntxt{\alpha} \ \wedge \ \bigvee_{\loc_i \in \Loc_i} \hspace*{-1ex} \al{\loc_i} \ 
  \wedge(\urg(\loc_i) + \hmin)\Big).
\end{displaymath}
where $\gamma(B_i)$ denotes the subset of interactions in which $B_i$ participates, that is, 
$\gamma(B_i) = \{ \beta \in \gamma \ | \ B_i \in \p{\beta} \}$.
Notice that the above expression strongly depends on the plan $\pi$, which is difficult to 
characterize in practice.
The following theorem proposes sufficient plan-independent condition characterizing 
action-time-lock states of the \lpsabrb.
\begin{theorem}\label{thm:dla}
  Let $\phi$ be the following predicate:
\begin{displaymath}
  \bigvee_{1\le i\le n}\Big[\bigvee_{\loc_i \in \Loc_i}\al{\loc_i}\ \wedge(\urg(\loc_i)+\hmin) \ 
  \wedge\bigwedge_{\alpha \in \gamma(B_i)}\hspace*{-1ex}\Big(  \neg\plntxt{\alpha} \
  \vee\hspace*{-2ex}\bigvee_{\substack{\beta\in\confl(\alpha)\\B_i\notin\p{\beta}}}\hspace*{-1ex}
  \stacktxt{\plntxt{\beta}} \Big)\Big].
\end{displaymath}
We prove that a reachable action-time-lock state $(\loc,\val,\pi)$ satisfies $\phi$.
\end{theorem}
\begin{proof}[Proof of Theorem~\ref{thm:dla}]
A reachable action-time-lock state of the \lpsabrb satisfies:
\begin{displaymath}
  \pi>0 \ \wedge \ \bigwedge_{\substack{\alpha \in \gamma(B_i) \setminus conf(\pi)}} 
  \hspace*{-4ex} \Big(\neg\plntxt{\alpha} \ \wedge \ \bigvee_{\substack{\loc_i \in \Loc_i \\ 
  B_i \notin \p{\pi}}} \hspace*{-1ex} \al{\loc_i} \ \wedge(\urg(\loc_i) + \hmin)\Big).
\end{displaymath}

In order to approximate the above formula, we distinguish two cases:
\paragraph*{Case 1: no interaction is planned (i.e. $\pi = \pi_0$)\\}
From $\pi = +\infty$ we deduce directly that there exists an urgent component $B_i$ 
such that no interaction $\alpha$
involving $B_i$ can be planned, that is:
\begin{equation}
\label{eq:case1}\tag{1}
\bigvee_{\substack{1\le i\le n}}\Big[\bigvee_{\loc_i \in \Loc_i}\al{\loc_i}\ \wedge(\urg(\loc_i)
  +\hmin) \ \wedge\bigwedge_{\substack{\alpha \in \gamma(B_i)}} \hspace*{-1ex}\neg\plntxt{\alpha}
  \Big].
\end{equation}

\paragraph*{Case 2: at least an interaction is planned (i.e. $\pi \neq\pi_0$)\\}
In this case, there exists an urgent component $B_i \notin \p{\pi}$ such that no interaction 
$\alpha$ involving $B_i$ can be planned, either because it conflicts with a planned interaction 
$\beta$ ($0<\pi(\beta)<+\infty$) or because $\plntxt{\alpha}$ is not satisfied, that is 
$\exists\beta\in\pi,\exists B_i\notin\p{\beta}$ satisfying:
\begin{displaymath}
  (0<\pi(\beta)<+\infty) \ \wedge\bigwedge_{\substack{\alpha \in \gamma(B_i) \setminus 
  conf(\beta)}} \hspace*{-4ex} \neg\plntxt{\alpha} \ \wedge \ \bigvee_{\substack{\loc_i \in 
  \Loc_i \\ B_i \notin \p{\beta}}} \hspace*{-1ex} \al{\loc_i} \ \wedge(\urg(\loc_i) + \hmin).
\end{displaymath}
or equivalently $\exists\beta\in\pi,\exists B_i\notin\p{\beta}$ satisfying:
\begin{displaymath}
  \bigvee_{\substack{\loc_i \in \Loc_i \\ B_i \notin \p{\beta}}} \hspace*{-1ex} \al{\loc_i} \ 
  \wedge(\urg(\loc_i) + \hmin) \ \wedge\bigwedge_{\alpha \in \gamma(B_i) }
 \Big(\neg\plntxt{\alpha}\vee\big(\beta\in\confl(\alpha)\wedge (0<\pi(\beta)<+\infty)\big)\Big) .
\end{displaymath}
By noticing that we have the following implication between quantifiers 
$\exists y,\forall x. Q(x,y)\implies\forall x,\exists y. Q(x,y)$, we can deduce that the 
above condition implies:
\begin{displaymath}
  \bigvee_{1\le i\le n}\Big[\bigvee_{\loc_i \in \Loc_i}\al{\loc_i}\ \wedge(\urg(\loc_i)+\hmin) \
  \wedge\bigwedge_{\alpha \in \gamma(B_i)}\hspace*{-1ex}\Big(  \neg\plntxt{\alpha} \
  \vee\hspace*{-2ex}\bigvee_{\substack{\beta\in\confl(\alpha)\\B_i\notin\p{\beta}}}\hspace*{-1ex}
0<\pi(\beta)<+\infty \Big)\Big].
\end{displaymath}


As $\pi > 0$, and if we consider only reachable action-time-locks, we have $0 < \pi(\beta) \leq
\hmax(\beta)$, and by Lemma~\ref{lem:pi_pln} we have $\plnIntxt{\beta}{\pi(\beta)}$.
That is, $\beta$ satisfies  $\plntxt{\beta}$ in which the lower bound $\hmin$ is replaced by the
strict lower bound 0, i.e.:
\begin{displaymath}
\stacktxt{\plntxt{\beta}} \Leftrightarrow \exists d > 0\ . \ d \leq \hmax(\beta) \ 
  \wedge \ \plnIntxt{\beta}{d}.
\end{displaymath}
Then, the above expression becomes:
\begin{equation}
  \label{eq:case2}\tag{2}
  \bigvee_{1\le i\le n}\Big[\bigvee_{\loc_i \in \Loc_i}\al{\loc_i}\ \wedge(\urg(\loc_i)+\hmin) \
  \wedge\bigwedge_{\alpha \in \gamma(B_i)}\hspace*{-1ex}\Big(  \neg\plntxt{\alpha} \
  \vee\hspace*{-2ex}\bigvee_{\substack{\beta\in\confl(\alpha)\\B_i\notin\p{\beta}}}\hspace*{-1ex}
  \stacktxt{\plntxt{\beta}} \Big)\Big].
\end{equation}

By remarking that Expression~\ref{eq:case1} implies Expression~\ref{eq:case2}, 
we can conclude that an action-time-lock of the \lps satisfies:
\begin{displaymath}
  \bigvee_{1\le i\le n}\Big[\bigvee_{\loc_i \in \Loc_i}\al{\loc_i}\ \wedge(\urg(\loc_i)+\hmin) \ 
  \wedge\bigwedge_{\alpha \in \gamma(B_i)}\hspace*{-1ex}\Big(  \neg\plntxt{\alpha} \
  \vee\hspace*{-2ex}\bigvee_{\substack{\beta\in\confl(\alpha)\\B_i\notin\p{\beta}}}\hspace*{-1ex}
  \stacktxt{\plntxt{\beta}} \Big)\Big].
\end{displaymath}
\end{proof}

Notice that due to the monotony of $\phi$ on upper bound horizons, we obtain the following lemma:

\begin{lemma}\label{lemma:mon}
  If $\tts_p$ is action-time-lock free for the upper bound horizons function $\hmax$, 
  then it is action-time-lock free for any upper bound horizon function $\hmax'\le\hmax$.
\end{lemma}

As explained earlier, a given system is deadlock free under
the restricted \lpsabrb if $Reach(\tts_p)\wedge\phi$ is unsatisfiable. Since
$Reach(\tts_p)\subseteq Reach(\tts_g)$ (Corollary~\ref{cr:sim}), we can verify the above on 
$Reach(\tts_g)$.
Effectively, we do not compute $Reach(\tts_g)$ to avoid the combinatorial explosion problem,
inherent to composition of timed automata. In fact, we rather build an over-approximation,
$\stacktxt{Reach(\tts_g)}$, of the latter, and use it during our verification.
Finding a strategy granting action-time-lock freedom is based on the idea of restricting
the upper bound horizon function $\hmax$. In fact, since $\hmin$ is a parameter that is 
dependent of the communication latency of a given execution platform, it cannot be tuned.
Instead, initially for each interaction $\alpha\in\gamma$, we put $\hmax(\alpha)=+\infty$. 
Thereafter,
due to the monotony of $\phi$ (Lemma~\ref{lemma:mon}) on upper horizons, this parameter will be 
refined, that is, its maximum will be decreased until finding a function $\hmax$ for which
$\reacha{\tts_g}\wedge\phi$ is unsatisfiable or until reaching the upper horizon function
$\hmaxm$ for which $\hmax(\alpha)=\hmin$ for every $\alpha\in\gamma$ and such that
$\reacha{\tts_g}\wedge\phi$ is satisfiable. 


\section{Planning Semantics as Real-Time Controller Synthesis}
\label{sec5}

In Section~\ref{sec5}, we presented a method that provides execution strategies
by restricting the upper bound planning horizons for each interaction. This strategy aims
to preserve the deadlock freedom property of a given system under the local planning semantics 
without imposing further scheduling constraints.
This approach relies on the verification of a given expression on over-approximation of the
reachable states of the initial semantics. Thus, it may give false-positive results due to
\emph{(i)} the nature of the expression to check (sufficient condition) and \emph{(ii)} the
over-approximation of the reachable states of the $\lpsabrb$ using over-approximations of 
the reachable states of the standard semantics (Corollary~\ref{cr:sim}). 

In such cases, an alternative is to tackle the problem as a real-time controller synthesis 
problem. Real-time controller synthesis is a common method used to extract an execution 
strategy from formal specifications satisfying certain properties. Usually, these properties 
express the reachability (resp. non-reachability) of a set of winning states (resp. bad states).
In case of planning interactions with bounded horizons, the idea is to restrict the 
transition relation so that all the remaining 
behaviors do not lead to states where a component is urgent and no possible execution
including this component may occur. This can be formalized as a reachability game for a timed
game automaton~\cite{tiga:alg}, where the main idea consists in trying to find an execution 
strategy guaranteeing that a given set of namely \emph{bad states} of the system are never
reached.

In order to apply this approach, it is required to encode the planning of interactions 
and their effects on the system, that is, \emph{(i)} encode interactions planning as 
synchronizations between components, \emph{(ii)} reserve the components of the planned 
interactions until their chosen execution date, i.e, keep track of the planned interactions 
and their execution dates, and \emph{(iii)} characterize the set of bad states. 
Thereafter, tools such as UPPAAL-Tiga~\cite{tiga} can be used to find an execution strategy of 
the planning semantics avoiding the set of bad states, that is, deadlock states.
Expressing the planning problem as a real-time controller synthesis problem is not 
an easy task. Hereinafter, we discuss the different issues met during the formalization 
process and provide suggestions for solving them.

\subsection{Encoding the Planning Semantics}

In order to encode the planning semantics, we rely on the idea of splitting each transition of 
the initial model into two transitions:
\emph{(1)} a planning transition, followed by \emph{(2)} an execution transition
after the plan transition being performed. 

\subsubsection{Planning Zones}

From~\ref{eq:pln}, we can see that the clocks values for planning an interaction 
$\alpha$ are calculated at a global level, that is, by applying the 
$\backwardp{\hmin}{\hmx}$ on the conjunction of its participating actions timing constraints.
Notice that for a timing constraint $g=g_1\wedge g_2$, we have:
\begin{equation}\label{eq:plz}
  \backwardp{\hmin}{\hmx} g=\backwardp{\hmin}{\hmx}(g_1\wedge g_2) \implies\backwardp{\hmin}{\hmx}
  g_1\wedge\backwardp{\hmin}{\hmx} g_2
\end{equation}

The above formula bears out the fact that planning states must be encoded on the composition
of the system model and not on individual components. Particularly, equation~\ref{eq:plz}
points out the fact that encoding the planning on transitions of individual components
will induce additional behavior ($\backwardp{\hmin}{\hmx}(g_1\wedge g_2) \implies
\backwardp{\hmin}{\hmx} g_1\wedge\backwardp{\hmin}{\hmx}g_2$). This represents the first 
drawback of
this method since building the composition may be tedious especially for big scale systems.
Therefore, a simple solution to avoid computing the composition is to consider
models with interactions having timing constraints on up to one of their participating
actions and that involves a single clock, that is, given an interaction 
$\alpha=\{a_i\}_{i\in I}\in\gamma$, we have $g_{\alpha}=\true$ or $g_{\alpha}=g_{a_i}$, with 
$g_{a_i}$ involving a single clock and $g_{a_j}=\true$ for $j\in I, j\neq i$.
In fact, considering interactions including up to one action with timing constraints involving 
a single clock, 
will allow to encode the planning on individual components that, additionally to the defined 
synchronizations (interactions), will also synchronize their planning actions. 

For an interaction $\alpha\in\gamma$, the choice
of the planning horizon, that is, the duration for which components participating in $\alpha$ 
will be blocked for until their execution, will be encoded on the execution transition of 
the component whose action $a_i\in\alpha$ and $g_{\alpha}=g_{a_i}$. Otherwise,
if $g_{\alpha}=\true$ this choice is made arbitrarily. Consequently, this component will be 
equipped with a clock $x_p$ that will be used to track the planning dates. 
Finally, location invariants must also be translated to enforce planning
at the latest $\hmin$ units of time before their expiry.
Figure~\ref{fig:enc} depicts an overview of such transformation for 
$\delta=2\times\hmin$ horizon: 
\input{./Figures/planEncode.tex}

\subsubsection{Infinite Planning Transitions} 

Effectively, in order to encode the planning in timed automata, horizons values must
be integer. Moreover, due to the dense time nature of the planning intervals (relative 
planning date for each interaction $\alpha$ are in $[\hmin,\hmax(\alpha)]$), we end up with 
an infinity of plan transitions, especially when not restricting upper bound planning horizons, 
i.e., $\hmax=\hmaxt$.
Consequently, the first thing to do is to restrict for each interaction $\alpha\in\gamma$ the
upper bound planning horizon $\hmax(\alpha)$.Thereafter, we propose to discretize the 
planning horizons in order to obtain finite values in $\integerpos$ (Figure~\ref{fig:disc}). 
In what follows, we denote by $Disc:\gamma\lto\mathcal{D}$ the discretized horizon function 
defining for each interaction its respective discretized planning horizons 
$\mathcal{D}\subset\integerpos$.

\input{./Figures/infinitPlan.tex}

\subsection{Planning Timed Automaton}

\begin{definition}[Planning Timed Automaton]
  \label{def:plan_aut}
  Given $n$ timed components $\tcal{B}_i=(\Loc_i,\loc_0^i,\A_i,\T_i,\X_i,\I_i)$ synchronizing 
  through the interaction set  $\gamma$ such that, for each interaction $\alpha\in\gamma$, 
  the guard of $\alpha$ is equal to the guard of one of its included actions.   
  We define the corresponding planning model as the composition of the n timed automata 
  $\tcal{B}_i^p=(\Loc_i^p,\loc_0,\A_i\cup\tcal{P}_i,\T_i^p,\X_i\cup\{x_i^p\},\I_i^p)$,
  w.r.t the interaction set $\gamma\cup\tcal{P}$, where:
  \begin{itemize}
    \item $\tcal{P}_i=\cup_{a\in\A_i} \ p_{a}$ is the set of \emph{Planning Actions}
    \item $\tcal{P}=\{p_{\alpha}=\{p_{a_i}\}_{i\in I}|\alpha\in\gamma\wedge\alpha=
      \{a_i\}_{i\in I}\}$ is the set of \emph{Planning Interactions}  
    \item $x_i^p$ is a \emph{Tracking Clock} for interactions execution in each component
    \item $\Loc_i^{p}=(\Loc_i\cup\Loc_{i_p})$ is the set of control locations, where 
      $\Loc_{i_p}$ is the set of locations following planning actions
    \item $\T_i^p$ is such that for each $(\loc_i,a_i,g_i,r_i,\loc'_i)\in\T_i$, $a_i\in\alpha$ 
      and for each
      $\delta\in Disc(\alpha)$:
      \begin{itemize}
        \item if $g_{\alpha}\neq\true$ we have:\\
          Planning transitions: $\begin{cases}
            \loc_i\transit{p_{a_i},\true,\emptyset}\loc_{a_i}, \text{ if } g=\true\\
            \loc_i\transit{p_{a_i},\backwardp{\delta}{\delta} g_i,r(x_i^p)}\loc^{\delta}_{a_i}, 
          \text{ otherwise}\end{cases}$\\ 
          Execution transitions: $\begin{cases}
            \loc_{a_i}\transit{a,\true,r_i}\loc'_i, \text{ if } g=\true\\
            \loc_{a_i}^{\delta}\transit{a,g_a\wedge x_i^p=\delta,r_i}\loc'_i, \text{ otherwise}
            \end{cases}$\\
            where $\loc_{a},\loc_{a_i}^{\delta}\in\Loc_{i_p}$.\\
        \item if $g_{\alpha}=\true$, we choose one action $b\in\alpha$:\\
           Planning transitions: $\begin{cases}
            \loc_i\transit{p_{a_i},\true,\emptyset}\loc_{a_i}, \text{ if } a\neq b\\
          \loc_i\transit{p_{a_i},\true,r(x_i^p)}\loc_{a_i}^{\delta}, \text{ otherwise}
           \end{cases}$\\ 
           Execution transitions: $\begin{cases}
            \loc_{a_i}\transit{a_i,\true,r_i}\loc'_i, \text{ if } a\neq b\\
            \loc_{a_i}^{\delta}\transit{a_i,g_i\wedge x_i^p=\delta,r_i}\loc'_i, \text{ otherwise}
            \end{cases}$\\
      \end{itemize}
    \item $\I_i^p$ is the set of \emph{Location Invariants} , such that 
      $\forall\loc_i^p\in\Loc_i^p$, we have:\\
      $\I_i^p(\loc_i^p)= \begin{cases}
        \I(\loc_i)-\hmin, \text{ if }\loc_i^p=\loc_i\in\Loc_i\\
        x_{i}^{p}\le\delta\wedge\I(\loc_i), \text{ if } \loc_i^p=\loc_{a_i}^{\delta}\in
        \Loc_{i_p}$ such that $\loc_i\in\Loc_i\wedge\loc_i\transit{p_{a_i}}\loc_{a_i}^{\delta},
      \end{cases}$
  \end{itemize}

\end{definition}

For a composition $\gamma(B_1,\cdots,B_n)$, let $\tts_{p'}=(\Q_{p'},\gamma'\cup\realpos,
\lto_{\gamma'})$, where $\gamma'=\gamma\cup\tcal{P}$, be the corresponding timed transition 
system of its planning model under the 
standard semantics.  
\begin{theorem}\label{correctness}
  $\tts_{p'}\simuw{R'}\tts_g$ where $R'$ is the relation defined as follows:
  For $q^p=(\loc^p,\val^p)\in\Q_{p'}$ and $q^g=(\loc^g,\val^g)\in\Q_g$, such that $(q^p,q^g)\in 
  R'$, we have: 

  \begin{itemize}
    \item $\loc^p=(\loc^p_1,\cdots,\loc^p_n),\ \loc_g=(\loc^g_1,\cdots,\loc^g_n)$:
      \[\forall i\in\{1,\cdots,n\},\ \loc^g_i=\begin{cases}
        \loc^p_i, \text{ if } \loc^p_i\in\Loc_i,\\
        \loc_i, \text{ if } \loc^p_i\in\Loc_{i_p}\text{ with }\loc_i\transit{a,g,r}\loc_i^p\in
        \T_i^p\wedge\loc_i\in\Loc_i,
    \end{cases} 
      \]
      Notice that for the case where $\loc_i^p\in\Loc_{i_p}$, $\loc_i$ is unique by 
      construction of the planning model.
    \item $\val^g=equ(\val^p)$, where $equ(\val^p)$ is the projection of $\val^p$ on clocks of 
      $\val^g$ 
  \end{itemize}
 
  \end{theorem}
  \begin{proof}[Proof of Theorem~\ref{correctness}]
    To prove that $\tts_{p'}\simuw{R'} \tts_g$, we need to prove that:

  \begin{enumerate}
    \item $\forall(q^p,q^g)\in R',\sigma\in\gamma\cup\realpos\text{ such that }q^p\transit{
        \sigma}_{\gamma'}q'^{p}\Rightarrow\exists q'^g.(q'^{p},q'^g)\in R'\wedge 
      q^g\transit{\sigma}_{\gamma}q'^g$
    \item $\forall(q^p,q^g)\in R',p_{\alpha}\in\tcal{P}\text{ such that }q^p\transit{
        p_{\alpha}}_{\gamma'}q'^{p}\Rightarrow(q'^{p},q^g)\in R'$ 
  \end{enumerate}

  \begin{enumerate}
    \item
  \begin{enumerate}
    \item Suppose that $(q^p,q^g)\in R',\sigma=\alpha\in\gamma$ and $q^p\transit{\alpha}_{
        \gamma'}q'^{p}$ with $q'^p=(({\loc'}_1^p,\cdots,{\loc'}_n^p),{\val'}^p)$. We have:
      $q^p\transit{\alpha}_{\gamma'}q'^{p}\Rightarrow g_{\alpha}$ is $\true$, and for 
      $\alpha=\{a_i\}_{i\in\I}$, by construction of the planning automaton, we have:
      $\loc_i^g\transit{a_i,g_i,r_i}{\loc'}_i^g$ such that ${\loc'}_i^g={\loc'}_i^p$. Moreover, 
     since the same clocks are reset by the execution of $\alpha$ in both models, we deduce 
      that $\val'^g=equ(\val'^p)$. 
      By remarking that the state of components not participating in $\alpha$ remains the same, 
      we conclude that $\exists {q'}^g$ such that 
      $q^g\transit{\alpha}_{\gamma}{q'}^g\wedge({q'}^p,{q'}^g)\in R'$. 
    \item Suppose that $(q^p,q^g)\in R',\sigma\in\realpos$ and $q^p\transit{\sigma}_{\gamma'}
      q'^{p}$. For $q^p_i=(\loc_i^p,\val_i^p)$, we define $\I_g$ the set of indexes such that 
       $\loc_i^p\in\Loc_i$, and $\I_p$ the set of indexes such that $\loc_i^p\in\Loc_{p_i}$. 
       \begin{itemize}
         \item $\forall i\in\I_g$.$\loc_i^p=\loc_i^g\wedge\q_i^p\transit{\sigma}
           {q'}_i^p\Rightarrow q_i^g\transit{\sigma}{q'}_i^g$. This implication is a direct 
           result of the planning model definition since: $\sigma\le\I(\loc_i^p)\le\I(
           \loc_i^g)-\hmin$.
         \item $\forall i\in\I_p.\loc_i^g=\loc_i$ such that $\loc^p_i\in\Loc_{i_p}\text{ with }
           \loc_i\transit{a,g,r}\loc_i^p\in\T_i^p\wedge\loc_i\in\Loc_i$.
           Thus $\q_i^p\transit{\sigma}{q'}_i^p\Rightarrow q_i^g\transit{\sigma}{q'}_i^g$, 
           since $\I(\loc_i^p)\implies\I(\loc_i^g)$.

         \end{itemize}
       We conclude that $\exists q'^g$ such that $q^g\transit{\sigma}_{\gamma}{q'}^g\wedge({q'}^
         p,{q'}^g)\in R'$.
  \end{enumerate}

\item Suppose that $(q^p,q^g)\in R'$ and $q^p\transit{p_{\alpha}}_{\gamma'}q'^{p}$, with 
  $p_{\alpha}\in\tcal{P}$ and $q'^p=(({\loc'}_1^p,\cdots,{\loc'}_n^p),{\val'}^p)$. We have:
      $q^p\transit{p_{\alpha}}_{\gamma'}q'^{p}\Rightarrow$ for $\alpha=\{a_i\}_{i\in\I}$
      $\loc_i^g=\loc_i^p\wedge\loc_i^g\transit{p_{a_i}}{\loc'}_i^p$. Moreover, since planning
      actions reset only the clocks $x_i^p$ for tracking execution time, we can deduce that
      $({q'}^p,q^g)\in R'$.
  \end{enumerate}

\end{proof}

\begin{figure}[ht] 
  \begin{minipage}[b]{0.5\linewidth}
  \centering
  \includegraphics[width=1.15\linewidth]{Figures/c.eps}\\ 
    (a) Controller Component 
  \vspace{4ex}
  \end{minipage}%%
  \begin{minipage}[b]{0.5\linewidth}
  \centering
  \includegraphics[width=.75\linewidth]{Figures/v.eps}\\ 
    (b) Variable Component 
  \vspace{4ex}
  \end{minipage} 
  \begin{minipage}[b]{\linewidth}
  \centering
  \includegraphics[width=0.75\linewidth]{Figures/t.eps}\\ 
    (c) Task Component 
  \vspace{4ex}
  \end{minipage}%% 
  \caption{Planning Automata for the Task Manager Example}
  \label{fig:uppaal} 
\end{figure}

Once interactions planning encoded, one last thing to do is to add the set of bad states to each
planning automaton (if needed) and find a strategy to avoid those states. 
Figure~\ref{fig:uppaal} depicts the corresponding planning automata for example of 
Figure~\ref{fig:tm} with respect to Definition~\ref{def:plan_aut}. 
Locations suffixed by \emph{p}, correspond to locations following 
planning actions, whereas locations ending with \emph{err} define the bad states, that is,
states with urgent location invariant(s) and no possible execution removing the urgency. 
In this example, for each interaction $\alpha\in\gamma$, we chose $\mathcal{D}(\alpha)=\{1,2\}$.
Notice that for this example, we consider that all actions are controllable actions since
it is a closed system in the sense that there is no interaction with the environment.

We performed the verification on the Task Manager examples with 20 tasks. The winning 
condition being a safety condition: avoid all \emph{\say{err}} locations. This was translated 
into the following property:
\begin{equation}\label{eq:avoid}
  \text{\textsf{control: A[ ] forall (i : int[0,N-1]) not (Task(i).l\_{2\_{err}} or 
  Task(i).l\_{3\_{err}})}}
\end{equation}

The property of interest was successfully verified. Additionally, we were also able to 
synthesize all wining actions of all states using the command line of UPPAAL-Tiga. A sample
of the resulting output is provided below Figures~\ref{fig:sample}.
Notice that the average execution time\footnote{The experiments have been conducted on a HP 
machine with Ubuntu 16.04, an Intel\textsuperscript{\textregistered} 
Core\textsuperscript{\texttrademark}i5-4300U processor of frequency 1.90GHz$\times$4, and
7.7GiB memory.} for verifying Property~\ref{eq:avoid} is $0.1141$ seconds
($0.6534$ seconds when requesting the generation of a strategy).
\begin{figure}[ht]
  \fbox{\begin{minipage}{40em}
    \texttt{State: ( Controller.l\_1\_p\_1 Task(0).l\_0 Task(1).l\_1\_p Task(2).l\_3\_p2 
  Task(3).l\_0 Task(4).l\_0 Task(5).l\_0 Task(6).l\_0 Task(7).l\_0 Task(8).l\_0 Task(9).l\_0 
  Task(10).l\_0 Task(11).l\_0 Task(12).l\_0 Task(13).l\_0 Task(14).l\_0 Task(15).l\_0 
  Task(16).l\_0 Task(17).l\_0 Task(18).l\_0 Task(19).l\_0 Var.V\_pe ) vlist[0]=2 vlist[1]=0
  vlist[2]=0 vlist[3]=0 vlist[4]=0 vlist[5]=0 vlist[6]=0 vlist[7]=0 vlist[8]=0 vlist[9]=0 
  vlist[10]=0 vlist[11]=0 vlist[12]=0 vlist[13]=0 vlist[14]=0 vlist[15]=0 vlist[16]=0 
  vlist[17]=0 vlist[18]=0 vlist[19]=0 vlen=1 Controller.list[0]=1 Controller.list[1]=0 
  Controller.list[2]=0 Controller.list[3]=0 Controller.list[4]=0 Controller.list[5]=0 
  Controller.list[6]=0 Controller.list[7]=0 Controller.list[8]=0 Controller.list[9]=0 
  Controller.list[10]=0 Controller.list[11]=0 Controller.list[12]=0 Controller.list[13]=0 
  Controller.list[14]=0 Controller.list[15]=0 Controller.list[16]=0 Controller.list[17]=0 
  Controller.list[18]=0 Controller.list[19]=0 Controller.len=1\\ 
  When you are in (Controller.zp==1 \&\& Task(2).yp<=2), take transition Controller.l\_1\_p\_1->
  Controller.l\_0 \{ zp == 1 \&\& 1 == front(), exec\_run[1]!, z := 0, dequeue() \}
  Task(1).l\_1\_p->Task(1).l\_2 \{ 1, exec\_run[id]?, y := 0, venqueue(id) \}
  When you are in (Task(2).yp==2 \&\& Controller.zp<=1), take transition Task(2).l\_3\_p2->
  Task(2).l\_0 \{ yp == 2, exec\_end[id]!, vdequeue() \}
  Var.V\_pe->Var.V\_ee \{ 2 == vfront(), exec\_end[2]?, 1 \}}
  \end{minipage}}
  \caption{Sample of the Output Strategy from UPPAAL-Tiga}
  \label{fig:sample}
\end{figure}


\subsection{Discussion}

In this section, we explained how the problem of planning interactions can be formalized into
a real-time controller synthesis approach. However, this approach has some drawbacks.
In order to encode planning of interactions in components as timed automata, this approach
restricts its scope to discretized horizon values which results in having less control
over the planning dates of interactions, and leads in case of a high number of discretized 
values, to an explosion in the number of planning transitions. Unfortunately, we do not 
have an immediate solution for this problem. In fact, it is user dependent since one user may 
just want to block components for the least amount of time possible for a given interaction, 
for instance because the components
involved in this interaction are often requested, and in that case the practice will be to 
always plan with $\hmin$. In other cases, the user may want to plan an interaction with 
flexible amount time.
Additionally, this approach considers only a class of systems where interactions have timing 
constraints on up to one of their participating components action. Otherwise, the planning 
should be encoded on the composition, which represents a tedious work because of the state 
space explosion problem. Nevertheless, this approach differs form the usual scheduler 
synthesis approach since it is not performed on the regular semantics of timed automata. 
Particularly, here we are interested in avoiding bad states of the planning semantics 
(states that verify the expression of Theorem~\ref{thm:dla}). Consequently, unless finding an 
automatic general method for generating such complex expressions in the query language accepted 
by such tools, and without ignoring that finding a strategy avoiding those states 
may be hard in terms of computational complexity, our real-time controller synthesis approach 
seems more straightforward and much simpler but it comes with some feasibility restriction.













